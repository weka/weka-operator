---
- name: Build lab VMs
  hosts: localhost
  tags: build_vms
  gather_facts: false
  tasks:
    - debug:
        var: frontend_lab_name
    - name: Lookup existing labs
      shell: "{{ teka }} lab list {{ frontend_lab_name }} --name-only || /usr/bin/true"
      args:
        chdir: "{{ wekapp_root }}"
      register: frontend_list
    - debug:
        var: frontend_list.stdout
    - name: Creating Lab
      shell: "{{ teka }} lab provision --size {{ frontend_cluster_size }} --os {{ os }} --env {{ env }} {{ frontend_lab_name }}"
      args:
        chdir: "{{ wekapp_root }}"
      when: frontend_list.stdout == ""
      register: create_frontent_lab_output
    - name: Lookup existing backend lab
      shell: "{{ teka }} lab list {{ backend_lab_name }} --name-only || /usr/bin/true"
      args:
        chdir: "{{ wekapp_root }}"
      register: backend_list
    - name: Creating Backend Lab
      shell: "{{ teka }} lab provision --size {{ backend_cluster_size }} --os ubuntu20 --env {{ env }} {{ backend_lab_name }}"
      args:
        chdir: "{{ wekapp_root }}"
      when: backend_list.stdout == ""
      register: create_backend_lab_output
    - name: Install Weka on Backend
      shell: "{{ teka }} install {{ backend_lab_name }}"
      args:
        chdir: "{{ wekapp_root }}"
      when: create_backend_lab_output is not skipped
- name: Wait for nodes to be ready
  hosts: oci_all
  tags: wait_ready
  gather_facts: false
  tasks:
    - name: Waiting for connection
      wait_for_connection:
        delay: 15
        sleep: 60
        timeout: 3600
        connect_timeout: 15

- name: Provision Frontend Nodes
  tags: provision_frontend
  hosts: frontend_hosts:&oci_all
  remote_user: root
  tasks:
    - name: Check access to public repos
      shell: "curl https://gcr.io/v1/_ping --write-out {{ '%{http_code}' }} --silent --output /dev/null"
      register: response_body
      failed_when: "'403' in response_body.stdout"
    - name: Set Hugepages
      shell: "echo 800 > /proc/sys/vm/nr_hugepages"
    - name: Download k3s
      get_url:
        url: https://get.k3s.io
        dest: /tmp/install_k3s.sh
    - name: Disable Firewall
      service:
        name: ufw
        enabled: false
        state: stopped

- name: Install Initial k8s Node
  tags: install_k8s_initial
  hosts: principal_frontend_host:&oci_all
  remote_user: root
  tasks:
    - name: Select Endpoint IP
      shell: "hostname -I | awk '{print $1}'"
      register: hostname_output
    - set_fact:
        endpoint_ip: "{{ hostname_output.stdout }}"
    - name: Uninstall Old K3s
      shell: /usr/local/bin/k3s-uninstall.sh
      args:
        removes: /usr/local/bin/k3s
    - name: Run Installer
      shell: "sh /tmp/install_k3s.sh server --cluster-init"
      args:
        creates: /usr/local/bin/k3s
    - name: Ensure k3s started
      service:
        name: k3s
        state: restarted
    - name: Generate Join Token
      slurp:
        src: /var/lib/rancher/k3s/server/token
      register: join_token_b64
    - set_fact:
        join_token: "{{ join_token_b64.content | b64decode }}"
    - name: Grab Kubeconfig
      slurp:
        path: /etc/rancher/k3s/k3s.yaml
      register: k3s_yaml_b64
    - name: Reading Kubeconfig
      set_fact:
        k3s_yaml: "{{ k3s_yaml_b64.content | b64decode | from_yaml }}"
    - name: Update K8s Endpoint
      ansible.utils.update_fact:
        updates:
          - path: "k3s_yaml.clusters[0].cluster.server"
            value: "https://{{ ansible_hostname }}:6443"
      register: local_k3s_yaml
    - name: Write local k3s.yaml
      copy:
        dest: "{{ root }}/k3s.yaml"
        content: "{{ local_k3s_yaml.k3s_yaml | to_yaml }}"
      delegate_to: localhost

- name: Join Secondary Nodes
  tags: join_secondaries
  hosts: secondary_frontend_hosts:&oci_all
  remote_user: root
  tasks:
    - set_fact:
        join_token: "{{ hostvars[groups['principal_frontend_host'][0]]['join_token'] }}"
    - debug:
        msg: "{{ hostvars[groups['principal_frontend_host'][0]]['endpoint_ip'] }}"
    - set_fact:
        principal_ip: "{{ hostvars[groups['principal_frontend_host'][0]]['endpoint_ip'] }}"
    - name: Uninstall Old K3s
      shell: /usr/local/bin/k3s-uninstall.sh
      args:
        removes: /usr/local/bin/k3s
    - name: Run Installer
      shell: "sh /tmp/install_k3s.sh server --server https://{{ principal_ip }}:6443 --token {{ join_token }}"
      args:
        creates: /usr/local/bin/k3s
      environment:
        K3S_TOKEN: "{{ join_token }}"
      register: k8s_install
      failed_when: k8s_install.rc > 1
      ignore_errors: true
    - debug:
        var: k8s_install.stdout_lines
      when: k8s_install.rc > 0
      failed_when: k8s_install is failed
    - name: Ensure k3s started
      service:
        name: k3s
        state: restarted

- name: Prlovision Backend Nodes
  tags: provision_backend
  hosts: backend_hosts:&oci_all
  vars:
    kernel_full_version: "{{ hostvars[groups['frontend_hosts'][0]].ansible_kernel }}"
    driver_root: "/opt/weka/dist/drivers"
  tasks:
    # tar each driver into file named <driver-name>-<weka-version>-<kernel-version>.<arch>.tar.gz
    # wekafs(gw|io) are packaged in a single tarball
    - name: Find wekafs drivers
      find:
        patterns:
          - "wekafs(gw|io).ko"
          - "igb_uio.ko"
          - "mpin_user.ko"
        paths: /opt/weka/data
        recurse: true
        use_regex: true
      register: drivers

    - name: Create driver directory
      file:
        path: "{{ driver_root }}"
        state: directory

    - name: Archive drivers
      archive:
        path: "{{ item.path }}"
        dest: "{{ driver_root }}/{{ item.path | basename | splitext | first }}-{{ weka_version }}-{{ kernel_full_version }}.x86_64.tar.gz"
        format: gz
        force_archive: true
      loop: "{{ drivers.files }}"

- name: Label Nodes
  tags: label_nodes
  hosts: frontend_hosts:&oci_all
  tasks:
    - name: Label nodes
      shell: "kubectl label nodes {{ ansible_hostname }} weka.io/role=client"

- name: Configuring Prerequisites in kubernetes
  tags: k8s_prerequisites
  hosts: localhost
  vars:
    dockerconfigjson_b64: "eyJhdXRocyI6eyJxdWF5LmlvIjp7InVzZXJuYW1lIjoibWF0dGhld19wZmVmZmVybGVfd2VrYSIsInBhc3N3b3JkIjoidC9sZVppOHVwQmo1c3hmOVg5RFkrK0h4RUlVNUQ2WFVRTHIxM203ZHNEdjlBclpoUW1UdVRyV1Bkc0lzTUdGM3I1UzAzWXFuSzZKZDZMeEFObnYxZEE9PSIsImF1dGgiOiJiV0YwZEdobGQxOXdabVZtWm1WeWJHVmZkMlZyWVRwMEwyeGxXbWs0ZFhCQ2FqVnplR1k1V0RsRVdTc3JTSGhGU1ZVMVJEWllWVkZNY2pFemJUZGtjMFIyT1VGeVdtaFJiVlIxVkhKWFVHUnpTWE5OUjBZemNqVlRNRE5aY1c1TE5rcGtOa3g0UVU1dWRqRmtRVDA5In19fQ=="
  tasks:
    - name: Creating operator namespace
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: namespace
          metadata:
            name: weka-operator-system
    - name: Creating image pull secret - quay-cred
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: quay-cred
            namespace: weka-operator-system
          type: kubernetes.io/dockerconfigjson
          data:
            .dockerconfigjson: "{{ dockerconfigjson_b64 }}"
    - name: Creating CLI Secret
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: weka-cli
            namespace: weka-operator-system
          type: kubernetes.io/basic-auth
          stringData:
            username: admin
            password: admin
