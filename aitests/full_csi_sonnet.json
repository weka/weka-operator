{
  "description": "Validate that WekaCluster, WekaClient, CSI, StorageClass, PVC, and workload can be provisioned and reach Ready state on a physical environment with 10.200.0.0/16 subnet.",
  "name": "weka_cluster_client_csi_workload_provisioning_test",
  "steps": [
    {
      "name": "create_namespace",
      "requirements": "Create a Kubernetes namespace with a 'test-' prefix (e.g., 'test-weka'). This namespace will be used for all subsequent resources. Use `kubectl create namespace <namespace_name>`. If namespace is not explicitly specified in the test scenario - create a namespace with test- prefixed name. All resources should be placed within this namespace. AIMUST: Only namespace specified in test scenario should be used for all actions, if namespace is not specified explicitly - create a namespace with test- prefixed name. All resources should be placed within this namespace.",
      "outputs": ["namespace"]
    },
    {
      "name": "generate_cluster_name",
      "requirements": "Generate a unique cluster name that starts with 'test-', is no longer than 32 characters, conforms to Kubernetes resource name conventions, and reflects the purpose of the test (e.g., 'test-wekacluster-basic'). Autogenerated part of name should not be longer than 16 characters. The name should be unique to avoid naming conflicts. AIMUST: generate cluster name as a separate and early step, so it will be used by reference in every later stage, including cluster create.",
      "outputs": ["cluster_name"]
    },
    {
      "name": "create_wekacluster_yaml",
      "requirements": "Create a WekaCluster YAML file based on the basic template from `cluster-provisioning.md`, adjusting the parameters as follows. Make sure to apply k8s wekacluster CR yaml to initiate provisioning of a cluster. The generated cluster yaml MUST be fully built yaml that will not undergo any more modifications and will be applied AS IS. WekaCluster should follow documentation example and not remove any fields, but only adjust values as needed/add new fields.\n\n```yaml\napiVersion: weka.weka.io/v1alpha1\nkind: WekaCluster\nmetadata:\n  name: $generate_cluster_name__cluster_name\n  namespace: $create_namespace__namespace\nspec:\n  template: dynamic\n  dynamicTemplate:\n    computeContainers: 8\n    driveContainers: 8\n    computeCores: 2\n    driveCores: 2\n    computeHugepages: 10000\n    numDrives: 2\n  hotSpare: 1\n  leadershipRaftSize: 5\n  bucketRaftSize: 5\n  redundancyLevel: 2\n  gracefulDestroyDuration: 0s\n  startIoConditions:\n    minNumDrives: 14\n  overrides: {}\n  image: quay.io/weka.io/weka-in-container:4.4.2.157-k8s.2\n  nodeSelector:\n    weka.io/dedicated: \"anton\"\n  driversDistService: \"https://weka-drivers-dist.weka-operator-system.svc.cluster.local:60002\"\n  imagePullSecret: \"quay-io-robot-secret\"\n  network:\n    deviceSubnets:\n      - 10.200.0.0/16\n```\n\nNote the following:\n- `apiVersion` is `weka.weka.io/v1alpha1`\n- `gracefulDestroyDuration` is set to `0s` for easier testing. Do not use in production.\n- `minNumDrives` should be in the range of 80% of `driveContainers` * `numDrives`\n- `nodeSelector` is set to `weka.io/dedicated: \"anton\"`\n- The `network` section is included with `deviceSubnets: - 10.200.0.0/16` as this is a physical environment. From `cluster-provisioning.md`: When cluster is deployed on physical environment, network section should be specified. On physical environment `ethDevice`, or `ethDevices`, or `deviceSubnets` should be used.\n\nSubstitute `$generate_cluster_name__cluster_name` and `$create_namespace__namespace` with the generated cluster name and created namespace respectively.",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["wekacluster_yaml"]
    },
    {
      "name": "apply_wekacluster",
      "requirements": "Apply the generated WekaCluster YAML using `kubectl apply -f <yaml_file> -n $create_namespace__namespace`. This will initiate the provisioning of the Weka cluster.  K8s resources yamls should be applied using `kubectl apply -f file.yaml` or other method that works against kubernetes API, just creating the files is never a purpose.",
      "inputs": ["create_wekacluster_yaml.wekacluster_yaml", "create_namespace.namespace"],
      "outputs": ["wekacluster_applied"]
    },
    {
      "name": "extract_cluster_uid",
      "requirements": "Extract the metadata.uid of the created WekaCluster. This UID is used to identify the cluster. Use the following command: `kubectl get wekacluster $generate_cluster_name__cluster_name -n $create_namespace__namespace -o jsonpath='{.metadata.uid}'`. NEVER select wekacontainer or pod without filtering by specific cluster-id (weka.io/cluster-id=wekacluster.metadat.uid) or by specific container name.",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["cluster_uid"]
    },
    {
      "name": "wait_for_wekacluster_ready",
      "requirements": "Poll the WekaCluster status until it reaches the 'Ready' state. Use the following command: `kubectl get wekacluster $generate_cluster_name__cluster_name -n $create_namespace__namespace -o jsonpath='{.status.status}'`. Check the status every 30 seconds for up to 10 minutes. From `cluster-provisioning.md`: After cluster was provisioned, a process can be observed by polling kubernetes api against wekacluster object, status.status field should reach Ready. If it does not reach 'Ready' within 10 minutes - consider it failed, but continue with the test execution.",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["wekacluster_ready"]
    },
    {
      "name": "create_wekaclient_yaml",
      "requirements": "Create a WekaClient YAML file based on the template from `k8s-wekaclient-and-workload.md`, adjusting the parameters as follows. When provisioning keep all fields as is, only adjust values as needed, but not remove existing fields, unless explicitly instructed.\n\n```yaml\napiVersion: weka.weka.io/v1alpha1\nkind: WekaClient\nmetadata:\n  name: $generate_cluster_name__cluster_name-clients\n  namespace: $create_namespace__namespace\nspec:\n  image: quay.io/weka.io/weka-in-container:4.4.2.157-k8s\n  imagePullSecret: \"quay-io-robot-secret\"\n  driversDistService: \"https://weka-drivers-dist.weka-operator-system.svc.cluster.local:60002\"\n  portRange:\n    basePort: 45000\n  nodeSelector:\n    weka.io/dedicated: \"anton\"\n  wekaSecretRef: weka-client-$generate_cluster_name__cluster_name\n  targetCluster:\n    name: $generate_cluster_name__cluster_name\n    namespace: $create_namespace__namespace\n  coresNum: 1\n  network:\n    deviceSubnets:\n      - 10.200.0.0/16\n```\n\nNote the following:\n- `nodeSelector` should be same as the one used for cluster: weka.io/dedicated: \"anton\"\n- `wekaSecretRef` is a reference to a secret created by wekacluster CR, in format of `weka-client-$generate_cluster_name__cluster_name`\n- `targetCluster` references the created WekaCluster by name and namespace\n- The `network` section is included with `deviceSubnets: - 10.200.0.0/16` as this is a physical environment. network section is optional, same as with wekacluster CR - mandatory for physical environment, optional for other environments.\n\nSubstitute `$generate_cluster_name__cluster_name` and `$create_namespace__namespace` with the generated cluster name and created namespace respectively.",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["wekaclient_yaml"]
    },
    {
      "name": "apply_wekaclient",
      "requirements": "Apply the generated WekaClient YAML using `kubectl apply -f <yaml_file> -n $create_namespace__namespace`. This will deploy the WekaClient.",
      "inputs": ["create_wekaclient_yaml.wekaclient_yaml", "create_namespace.namespace"],
      "outputs": ["wekaclient_applied"]
    },
    {
      "name": "wait_for_wekaclient_containers",
      "requirements": "Wait for all WekaClient containers to be in Running state.  Find WekaClient containers using: `kubectl get pods -n $create_namespace__namespace -l weka.io/client-name=$generate_cluster_name__cluster_name-clients,weka.io/mode=client`. Verify that all the pods are in the Running state. Check every 30 seconds for up to 5 minutes. From `k8s-wekaclient-and-workload.md`:Filtering of wekaclient containers should be done only by weka.io/client-name=WEKACLIENT_RESOURCE_NAME and weka.io/model=client labels",
      "inputs": ["create_namespace.namespace", "generate_cluster_name.cluster_name"],
      "outputs": ["client_containers_joined"]
    },
    {
      "name": "verify_client_connectivity",
      "requirements": "Verify client connectivity by executing 'weka status' inside a compute container. First, find a compute container using: `kubectl get pods -n $create_namespace__namespace -l weka.io/mode=compute,weka.io/cluster-id=$extract_cluster_uid__cluster_uid -o name`. Then execute: `kubectl exec -n $create_namespace__namespace <pod_name> -- weka status`. Parse the output of `weka status` to verify that the number of connected clients is as expected. From `k8s-wekaclient-and-workload.md`: wekaclient might be scheduled on same set of nodes as backends, or dedicated nodes just for clients. when referencing as \"client\" a meaning usually is a wekacontainer of type weka.io/mode=client which provisioned by wekaclient CR\nAlso, from `weka-cluster.md` example of `weka status` output:\n```\n       cluster: cluster-name (550c68b6-8f64-4073-8086-efc3ba69207e)\n        status: OK (17/21 backend containers UP, 36 drives UP)\n    protection: 3+2 (Fully protected)\n     hot spare: 0 failure domains\n drive storage: 210.59 TiB total, 209.00 TiB unprovisioned\n         cloud: connected\n       license: Unlicensed\n\n     io status: STARTED 19 days ago (29/33 io-nodes UP, 156 Buckets UP)\n    link layer: Ethernet\n       clients: 4 connected\n         reads: 0 B/s (0 IO/s)\n        writes: 0 B/s (0 IO/s)\n    operations: 6 ops/s\n        alerts: 52 active alerts, use `weka alerts` to list them\n```\nStatuses such as OK, REDISTRIBUTING, PARTIALLY_PROTECTED, REBUILDING considered healthy",
      "inputs": ["extract_cluster_uid.cluster_uid", "create_namespace.namespace"],
      "outputs": ["client_connectivity_verified"]
    },
    {
      "name": "create_csi_values",
      "requirements": "Create a `csi_values.yaml` file with the following content, replacing `$generate_cluster_name__cluster_name` with the generated cluster name:\n\n```yaml\npluginConfig:\n  allowInsecureHttps: true\n  skipGarbageCollection: true\ncontrollerPluginTolerations:\n - operator: Exists\nnodePluginTolerations:\n - operator: Exists\ncontroller:\n  nodeSelector:\n    \"weka.io/dedicated\": \"anton\"\nnode:\n  nodeSelector:\n    \"weka.io/dedicated\": \"anton\"\ncsiDriverName: $generate_cluster_name__cluster_name.weka.io\n```\nFrom `k8s-wekaclient-and-workload.md`: nodeSelector on both node and controller MUST match values that were used on the level of wekaClient CR . csiDriverName must match format of CLUSTER_NAME.weka.io",
      "inputs": ["generate_cluster_name.cluster_name"],
      "outputs": ["csi_values_yaml"]
    },
    {
      "name": "install_csi_driver",
      "requirements": "Install the CSI driver using Helm with the following command:\n`helm upgrade csi-$generate_cluster_name__cluster_name -n $create_namespace__namespace --create-namespace -i https://csi-wekafs-plugin-helm.s3.eu-west-1.amazonaws.com/csi-wekafsplugin-2.6.3-sergeynoderemovetopologywhenun.36.88fde58.tgz -set logLevel=6 --values $create_csi_values__csi_values_yaml`.  Validate that all pods in NAMESPACE $create_namespace__namespace with label `release=csi-$generate_cluster_name__cluster_name` reach Running state within 1 minute after running `helm upgrade`.  From `k8s-wekaclient-and-workload.md`: helm should be executed via bash tool, and installation should be validated by validating all pods in NAMESPACE with label release=release: csi-CLUSTER_NAME reaching Running step within 1 minute after running `helm upgrade`",
      "inputs": ["create_csi_values.csi_values_yaml", "create_namespace.namespace", "generate_cluster_name.cluster_name"],
      "outputs": ["csi_driver_installed"]
    },
    {
      "name": "create_storage_class_yaml",
      "requirements": "Create a StorageClass YAML file with the following content, replacing `$generate_cluster_name__cluster_name` and `$create_namespace__namespace` with the appropriate values. From `k8s-wekaclient-and-workload.md`: Unless instructed explicitly for specific values to override, use storage class as following, replacing CLUSTER_NAME and CLUSTER_NAMESPACE with actual values\n\n```yaml\nallowVolumeExpansion: true\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: weka-$generate_cluster_name__cluster_name-forcedirect\nparameters:\n  capacityEnforcement: HARD\n  csi.storage.k8s.io/controller-expand-secret-name: weka-csi-$generate_cluster_name__cluster_name\n  csi.storage.k8s.io/controller-expand-secret-namespace: $create_namespace__namespace\n  csi.storage.k8s.io/controller-publish-secret-name: weka-csi-$generate_cluster_name__cluster_name\n  csi.storage.k8s.io/controller-publish-secret-namespace: $create_namespace__namespace\n  csi.storage.k8s.io/node-publish-secret-name: weka-csi-$generate_cluster_name__cluster_name\n  csi.storage.k8s.io/node-publish-secret-namespace: $create_namespace__namespace\n  csi.storage.k8s.io/node-stage-secret-name: weka-csi-$generate_cluster_name__cluster_name\n  csi.storage.k8s.io/node-stage-secret-namespace: $create_namespace__namespace\n  csi.storage.k8s.io/provisioner-secret-name: weka-csi-$generate_cluster_name__cluster_name\n  csi.storage.k8s.io/provisioner-secret-namespace: $create_namespace__namespace\n  filesystemName: default\n  mountOptions: forcedirect\n  volumeType: dir/v1\nprovisioner: $generate_cluster_name__cluster_name.weka.io\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\n```",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["storage_class_yaml"]
    },
    {
      "name": "apply_storage_class",
      "requirements": "Apply the generated StorageClass YAML using `kubectl apply -f <yaml_file>`. This will create the StorageClass.",
      "inputs": ["create_storage_class_yaml.storage_class_yaml"],
      "outputs": ["storage_class_applied"]
    },
    {
      "name": "create_pvc_yaml",
      "requirements": "Create a PVC YAML file with the following content, replacing `$generate_cluster_name__cluster_name` and `$create_namespace__namespace` with the appropriate values. From `k8s-wekaclient-and-workload.md`:After storage class is created, create and apply a PVC, for example:\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: $generate_cluster_name__cluster_name-goader-pvc\n  namespace: $create_namespace__namespace\nspec:\n  accessModes:\n    - ReadWriteMany\n  storageClassName: weka-$generate_cluster_name__cluster_name-forcedirect\n  resources:\n    requests:\n      storage: 500Gi\n```",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["pvc_yaml"]
    },
    {
      "name": "apply_pvc",
      "requirements": "Apply the generated PVC YAML using `kubectl apply -f <yaml_file>`. Then, monitor the PVC status using `kubectl get pvc $generate_cluster_name__cluster_name-goader-pvc -n $create_namespace__namespace` to ensure that it reaches the 'Bound' state within 2 minutes. From `k8s-wekaclient-and-workload.md`: Ensure that PVC is bound(wait up to 2 minutes, if not bound - there is an issue)",
      "inputs": ["create_pvc_yaml.pvc_yaml", "generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["pvc_bound"]
    },
    {
      "name": "create_workload_yaml",
      "requirements": "Create a DaemonSet YAML file for the goader workload with the following content, replacing `$generate_cluster_name__cluster_name` and `$create_namespace__namespace` with the appropriate values. From `k8s-wekaclient-and-workload.md`: node selector on workload should match node selector used on wekaclient CR. After PVC is bound, it is possible to schedule workload, for example:\n\n```yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: goader-smallios-$generate_cluster_name__cluster_name\n  namespace: $create_namespace__namespace\n  labels:\n    app: goader-smallios-$generate_cluster_name__cluster_name\n    cluster: $generate_cluster_name__cluster_name\nspec:\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 100%\n  selector:\n    matchLabels:\n      app: goader-smallios-$generate_cluster_name__cluster_name\n      cluster: $generate_cluster_name__cluster_name\n  template:\n    metadata:\n      labels:\n        app: goader-smallios-$generate_cluster_name__cluster_name\n        cluster: $generate_cluster_name__cluster_name\n    spec:\n      nodeSelector:\n        \"weka.io/dedicated\": \"anton\"\n      containers:\n        - name: goader\n          imagePullPolicy: Always\n          image: public.ecr.aws/weka/goader:latest\n          env:\n            - name: GOADER_PARAMS\n              value: \"-wt=2 -rt=2 --body-size=128KiB --show-progress=False --max-requests=50000 --mkdirs --url /data/small/${NODE_NAME}/NN/NNN/NN\"\n            - name: NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n          volumeMounts:\n            - name: goader-storage\n              mountPath: /data\n      volumes:\n        - name: goader-storage\n          persistentVolumeClaim:\n            claimName: $generate_cluster_name__cluster_name-goader-pvc\n```\nEnsure the node selector matches the one used for the WekaClient CR.",
      "inputs": ["generate_cluster_name.cluster_name", "create_namespace.namespace"],
      "outputs": ["workload_yaml"]
    },
    {
      "name": "apply_workload",
      "requirements": "Apply the generated workload YAML using `kubectl apply -f <yaml_file>`. Monitor the pod status using `kubectl get pods -n $create_namespace__namespace -l app=goader-smallios-$generate_cluster_name__cluster_name` to ensure that all pods reach the Running state. If they are stuck in Pending or other state - something is wrong. From `k8s-wekaclient-and-workload.md`: if goader pods reached Running state, it is working as expected. If they are stuck in Pending or other state - something is wrong",
      "inputs": ["create_workload_yaml.workload_yaml", "create_namespace.namespace", "generate_cluster_name.cluster_name"],
      "outputs": ["workload_running"]
    }
  ],
  "documentation": "This test validates the end-to-end provisioning of Weka components on a physical environment with 10.200.0.0/16 subnet. It provisions a WekaCluster CR with 8 compute and 8 drive containers, redundancy level 2, hot spare 1, leadership raft size 5, bucket raft size 5, and minNumDrives set to 14. It then provisions a WekaClient CR with 1 core and verifies connectivity. Finally, it sets up CSI, StorageClass, PVC, and a goader workload to ensure full functionality. All resources use nodeSelector weka.io/dedicated: anton. IMPORTANT: Do not delete the WekaCluster or any other Kubernetes resources after the test, regardless of the outcome. This tests run on physical environment, use 10.200.0.0/16 subnet for testing. use weka.io/mode=compute|drive,weka.io/cluster-id=<cluster-id> to filter compute and drive containers cluster id references to kubernetes metadata.uid. use nodeSelector weka.io/dedicated=anton for all objects so no resources will be provisioned on nodes that do not match this selector"
}